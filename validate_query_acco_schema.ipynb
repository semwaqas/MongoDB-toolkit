{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bson import ObjectId, DBRef, MinKey, MaxKey, Timestamp, Int64, Decimal128, Binary, Code, Regex\n",
    "from collections.abc import Mapping, Sequence # Use abc for broader type checks\n",
    "\n",
    "def get_value_type_name(value):\n",
    "    \"\"\"Maps Python types commonly found in queries to BSON type names.\"\"\"\n",
    "    if isinstance(value, str): return \"string\"\n",
    "    if isinstance(value, bool): return \"bool\"\n",
    "    # Important: Check Int64 before int if you might have large numbers\n",
    "    if isinstance(value, Int64): return \"long\"\n",
    "    if isinstance(value, int): return \"int\" # Could be Int32 or Int64 in BSON\n",
    "    if isinstance(value, float): return \"double\"\n",
    "    if isinstance(value, Decimal128): return \"decimal\"\n",
    "    # Check Sequence *before* Mapping/dict, but exclude str/bytes\n",
    "    if isinstance(value, Sequence) and not isinstance(value, (str, bytes, bytearray)): return \"array\"\n",
    "    if isinstance(value, Mapping): return \"object\" # Check Mapping for dict-like\n",
    "    if isinstance(value, ObjectId): return \"objectId\"\n",
    "    if isinstance(value, DBRef): return \"dbRef\"\n",
    "    if isinstance(value, Timestamp): return \"timestamp\"\n",
    "    if isinstance(value, type(None)): return \"null\"\n",
    "    if isinstance(value, MinKey): return \"minKey\"\n",
    "    if isinstance(value, MaxKey): return \"maxKey\"\n",
    "    if isinstance(value, (bytes, Binary)): return \"binData\" # Treat bytes as binData\n",
    "    if isinstance(value, Code): return \"javascript\"\n",
    "    # isinstance(value, Regex) doesn't work directly for re.Pattern\n",
    "    if isinstance(value, Regex) or hasattr(value, 'pattern'): return \"regex\"\n",
    "    # Add datetime, etc. if needed\n",
    "    # Fallback\n",
    "    return type(value).__name__\n",
    "\n",
    "# List of common MongoDB query operators (add more if needed)\n",
    "QUERY_OPERATORS = {\n",
    "    '$eq', '$ne', '$gt', '$gte', '$lt', '$lte', '$in', '$nin',\n",
    "    '$exists', '$type',\n",
    "    '$mod', '$regex', '$options', '$text', '$search', '$where',\n",
    "    # Array operators\n",
    "    '$all', '$elemMatch', '$size',\n",
    "    # Logical operators\n",
    "    '$and', '$or', '$not', '$nor',\n",
    "    # Geospatial, Bitwise, etc. can be added here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Logic\n",
    "\n",
    "def validate_query(query_doc, expected_schema):\n",
    "    \"\"\"\n",
    "    Validates a MongoDB query document against an expected schema definition.\n",
    "\n",
    "    Args:\n",
    "        query_doc (dict): The MongoDB query filter document.\n",
    "        expected_schema (dict): The schema definition (output similar to the inference script).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings describing validation errors. An empty list means valid.\n",
    "    \"\"\"\n",
    "    if not isinstance(query_doc, Mapping):\n",
    "        return [\"Query document must be a dictionary-like object.\"]\n",
    "    if not isinstance(expected_schema, Mapping):\n",
    "         return [\"Expected schema must be a dictionary-like object.\"]\n",
    "\n",
    "    errors = []\n",
    "    _validate_recursive(query_doc, expected_schema, errors, path_prefix=\"\", full_schema=expected_schema)\n",
    "    return errors\n",
    "\n",
    "def _validate_recursive(query_part, schema_part, errors, path_prefix, full_schema):\n",
    "    \"\"\"Recursive helper for validation.\"\"\"\n",
    "\n",
    "    if not isinstance(query_part, Mapping):\n",
    "        # This case should ideally not be hit for the top-level query_doc,\n",
    "        # but might occur in $not or other nested scenarios incorrectly.\n",
    "        errors.append(f\"Invalid query structure at '{path_prefix}': Expected a dictionary, got {type(query_part).__name__}.\")\n",
    "        return\n",
    "\n",
    "    for key, query_value in query_part.items():\n",
    "        current_path = f\"{path_prefix}.{key}\" if path_prefix else key\n",
    "\n",
    "        # Handle Logical Operators\n",
    "        if key in ('$and', '$or', '$nor'):\n",
    "            if not isinstance(query_value, Sequence) or isinstance(query_value, (str, bytes)):\n",
    "                errors.append(f\"Invalid value for operator '{key}' at '{current_path}': Expected an array of query documents.\")\n",
    "                continue\n",
    "            if not query_value:\n",
    "                 errors.append(f\"Warning: Operator '{key}' at '{current_path}' has an empty array.\")\n",
    "                 continue\n",
    "            # Validate each sub-query against the *full schema*\n",
    "            for i, sub_query in enumerate(query_value):\n",
    "                sub_path = f\"{current_path}[{i}]\"\n",
    "                if not isinstance(sub_query, Mapping):\n",
    "                     errors.append(f\"Invalid element in '{key}' array at '{sub_path}': Expected a query document (dict).\")\n",
    "                     continue\n",
    "                # Recursive call to the *top-level* validator for each item in $and/$or/$nor\n",
    "                _validate_recursive(sub_query, full_schema, errors, path_prefix=f\"{sub_path}\", full_schema=full_schema)\n",
    "            continue # Handled this logical operator key\n",
    "\n",
    "        if key == '$not':\n",
    "             # $not can contain a regex or an operator expression\n",
    "             # We need the schema context of the *field* it applies to, which isn't directly here.\n",
    "             # This requires rethinking how $not is handled, maybe pass parent schema context?\n",
    "             # For now, let's do a basic check if it's a dict\n",
    "             if not isinstance(query_value, Mapping):\n",
    "                 errors.append(f\"Invalid value for operator '$not' at '{current_path}': Expected an operator expression (dict).\")\n",
    "             else:\n",
    "                 # We can't fully validate the inner part without knowing which field's schema applies.\n",
    "                 # A simple heuristic: check if keys inside are operators. This is weak.\n",
    "                 inner_keys = list(query_value.keys())\n",
    "                 if not all(k.startswith('$') for k in inner_keys):\n",
    "                      errors.append(f\"Warning: Value for '$not' at '{current_path}' contains non-operator keys. Validation might be incomplete.\")\n",
    "                 # A full implementation would need the schema_part of the field being negated.\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Handle Field Names (Potentially with Dot Notation)\n",
    "        field_schema_info = None\n",
    "        current_schema_level = schema_part\n",
    "\n",
    "        # Handle dot notation (e.g., \"address.city\")\n",
    "        parts = key.split('.')\n",
    "        valid_path = True\n",
    "        temp_path_prefix = path_prefix # Track path within dot notation traversal\n",
    "\n",
    "        for i, part in enumerate(parts):\n",
    "            if not isinstance(current_schema_level, Mapping):\n",
    "                 errors.append(f\"Invalid query path '{current_path}': Trying to access field '{part}' within a non-object schema part at '{temp_path_prefix}'.\")\n",
    "                 valid_path = False\n",
    "                 break\n",
    "\n",
    "            if part not in current_schema_level:\n",
    "                # Check if the key is actually an operator applied to the *parent* object/doc\n",
    "                # This happens if schema_part is the schema for a document, and key is like '$expr'\n",
    "                if part.startswith('$') and i == 0: # Only check operators at the first level of split\n",
    "                     # Let operator handling below deal with it, but need parent context. Difficult here.\n",
    "                     # For simplicity, we'll assume dot notation *only* refers to nested fields for now.\n",
    "                      errors.append(f\"Invalid query key '{current_path}': Field '{part}' not found in schema at '{temp_path_prefix}'. Is it a misplaced operator?\")\n",
    "\n",
    "                else:\n",
    "                    errors.append(f\"Invalid query key '{current_path}': Field '{part}' not found in schema at '{temp_path_prefix}'.\")\n",
    "\n",
    "                valid_path = False\n",
    "                break\n",
    "\n",
    "            # Get the schema for this part\n",
    "            field_schema_info = current_schema_level[part]\n",
    "\n",
    "            # Check if we have the necessary nested schema info ('schema' for objects)\n",
    "            if i < len(parts) - 1: # If not the last part, we need to traverse deeper\n",
    "                temp_path_prefix = f\"{temp_path_prefix}.{part}\" if temp_path_prefix else part\n",
    "                if 'object' not in field_schema_info.get('types', set()):\n",
    "                    errors.append(f\"Invalid query path '{current_path}': Field '{part}' at '{temp_path_prefix}' is not defined as an 'object' in the schema, cannot traverse further.\")\n",
    "                    valid_path = False\n",
    "                    break\n",
    "                if 'schema' not in field_schema_info:\n",
    "                    errors.append(f\"Schema definition error: Field '{part}' at '{temp_path_prefix}' is an 'object' but lacks a 'schema' definition.\")\n",
    "                    valid_path = False\n",
    "                    break\n",
    "                current_schema_level = field_schema_info['schema']\n",
    "            else:\n",
    "                 # This is the final part of the key, field_schema_info holds its definition\n",
    "                 pass\n",
    "\n",
    "        if not valid_path:\n",
    "            continue # Skip validation for this key if path was invalid\n",
    "\n",
    "        # We found the schema definition for the final field ('field_schema_info')\n",
    "\n",
    "        # Check if the query value is a direct match or uses operators\n",
    "        if isinstance(query_value, Mapping) and any(k.startswith('$') for k in query_value.keys()):\n",
    "            # Value contains operators ($eq, $gt, $in, $elemMatch, etc.)\n",
    "            for op, op_value in query_value.items():\n",
    "                op_path = f\"{current_path}.{op}\"\n",
    "\n",
    "                if op not in QUERY_OPERATORS:\n",
    "                    errors.append(f\"Unknown operator '{op}' used at '{op_path}'.\")\n",
    "                    continue\n",
    "\n",
    "                # Operator-Specific Validation\n",
    "                allowed_types = field_schema_info.get('types', set())\n",
    "                element_schema = field_schema_info.get('element_schema', None) # For array fields\n",
    "\n",
    "                if op in ('$eq', '$ne', '$gt', '$gte', '$lt', '$lte'):\n",
    "                    op_value_type = get_value_type_name(op_value)\n",
    "                    if not allowed_types:\n",
    "                         errors.append(f\"Schema definition error at '{current_path}': Field lacks 'types' definition.\")\n",
    "                    elif op_value_type not in allowed_types and 'null' not in allowed_types : # Allow comparison with null if null is allowed type\n",
    "                         # Special case: Allow int/long/double/decimal to be compared somewhat interchangeably if any numeric type is allowed\n",
    "                         numeric_types = {'int', 'long', 'double', 'decimal'}\n",
    "                         if not (op_value_type in numeric_types and bool(allowed_types.intersection(numeric_types))):\n",
    "                             errors.append(f\"Type mismatch for operator '{op}' at '{op_path}': Query uses type '{op_value_type}', but schema expects {allowed_types}.\")\n",
    "\n",
    "                elif op in ('$in', '$nin'):\n",
    "                    if not isinstance(op_value, Sequence) or isinstance(op_value, (str, bytes)):\n",
    "                        errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected an array.\")\n",
    "                        continue\n",
    "                    if not allowed_types:\n",
    "                         errors.append(f\"Schema definition error at '{current_path}': Field lacks 'types' definition.\")\n",
    "                         continue\n",
    "                    for i, item in enumerate(op_value):\n",
    "                        item_type = get_value_type_name(item)\n",
    "                        item_path = f\"{op_path}[{i}]\"\n",
    "                        if item_type not in allowed_types and not (item_type == 'null' and 'null' in allowed_types):\n",
    "                             numeric_types = {'int', 'long', 'double', 'decimal'}\n",
    "                             if not (item_type in numeric_types and bool(allowed_types.intersection(numeric_types))):\n",
    "                                errors.append(f\"Type mismatch for item in '{op}' array at '{item_path}': Item type is '{item_type}', but schema expects {allowed_types}.\")\n",
    "\n",
    "                elif op == '$exists':\n",
    "                    if not isinstance(op_value, bool):\n",
    "                        errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected boolean (true/false).\")\n",
    "\n",
    "                elif op == '$type':\n",
    "                    # Value can be BSON type string or number\n",
    "                    valid_type_spec = False\n",
    "                    if isinstance(op_value, str): # BSON type alias\n",
    "                        valid_type_spec = True # Assume string alias is potentially valid\n",
    "                    elif isinstance(op_value, int): # BSON type number\n",
    "                         valid_type_spec = True # Assume number is potentially valid\n",
    "                    else:\n",
    "                         errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected BSON type string (e.g., 'string') or number (e.g., 2).\")\n",
    "\n",
    "                    if valid_type_spec and allowed_types:\n",
    "                         # Simple check: if $type requests a type not listed in schema's *possible* types, it's likely an issue.\n",
    "                         # Note: This is tricky as $type checks the *actual* BSON type.\n",
    "                         requested_type_str = str(op_value) # Crude check\n",
    "                         if requested_type_str not in allowed_types and op_value not in allowed_types:\n",
    "                            # Basic check - might need refinement based on BSON numbers vs names\n",
    "                            errors.append(f\"Warning: Operator '{op}' at '{op_path}' checks for type '{op_value}', which might not be among the expected schema types {allowed_types}.\")\n",
    "\n",
    "                elif op == '$regex':\n",
    "                     if 'string' not in allowed_types:\n",
    "                         errors.append(f\"Usage warning for operator '{op}' at '{op_path}': Field type is not 'string' in schema ({allowed_types}), $regex might not work as expected.\")\n",
    "                     if not isinstance(op_value, (str, Regex, re.Pattern)):\n",
    "                          errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected a string or regex pattern.\")\n",
    "                     # Could also validate '$options' if present in query_value dict\n",
    "\n",
    "                elif op == '$size':\n",
    "                     if 'array' not in allowed_types:\n",
    "                         errors.append(f\"Usage error for operator '{op}' at '{op_path}': Field type is not 'array' in schema ({allowed_types}).\")\n",
    "                     if not isinstance(op_value, int):\n",
    "                          errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected an integer size.\")\n",
    "\n",
    "                elif op == '$all':\n",
    "                     if 'array' not in allowed_types:\n",
    "                         errors.append(f\"Usage error for operator '{op}' at '{op_path}': Field type is not 'array' in schema ({allowed_types}).\")\n",
    "                     elif not isinstance(op_value, Sequence) or isinstance(op_value, (str, bytes)):\n",
    "                         errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected an array of elements.\")\n",
    "                     elif element_schema:\n",
    "                         # Validate each item in $all against the element schema\n",
    "                         elem_allowed_types = element_schema.get('types', set())\n",
    "                         if not elem_allowed_types:\n",
    "                             errors.append(f\"Schema definition error at '{current_path}': Array field lacks 'element_schema' with 'types'.\")\n",
    "                             continue\n",
    "                         for i, item in enumerate(op_value):\n",
    "                             item_type = get_value_type_name(item)\n",
    "                             item_path = f\"{op_path}[{i}]\"\n",
    "                             if item_type not in elem_allowed_types and not (item_type == 'null' and 'null' in elem_allowed_types):\n",
    "                                 numeric_types = {'int', 'long', 'double', 'decimal'}\n",
    "                                 if not (item_type in numeric_types and bool(elem_allowed_types.intersection(numeric_types))):\n",
    "                                     errors.append(f\"Type mismatch for item in '{op}' array at '{item_path}': Item type is '{item_type}', but array element schema expects {elem_allowed_types}.\")\n",
    "                     else:\n",
    "                          errors.append(f\"Schema definition error at '{current_path}': Array field lacks 'element_schema' definition needed to validate '{op}'.\")\n",
    "\n",
    "\n",
    "                elif op == '$elemMatch':\n",
    "                     if 'array' not in allowed_types:\n",
    "                         errors.append(f\"Usage error for operator '{op}' at '{op_path}': Field type is not 'array' in schema ({allowed_types}).\")\n",
    "                     elif not isinstance(op_value, Mapping):\n",
    "                         errors.append(f\"Invalid value for operator '{op}' at '{op_path}': Expected a query document (dict) for element matching.\")\n",
    "                     elif element_schema:\n",
    "                         # The element schema might be a primitive type or an object\n",
    "                         elem_types = element_schema.get('types', set())\n",
    "                         if 'object' in elem_types:\n",
    "                             # Validate the $elemMatch query against the element's object schema\n",
    "                             nested_elem_schema = element_schema.get('schema')\n",
    "                             if nested_elem_schema:\n",
    "                                 _validate_recursive(op_value, nested_elem_schema, errors, path_prefix=f\"{op_path}\", full_schema=full_schema) # Pass full_schema for logical operators within $elemMatch\n",
    "                             else:\n",
    "                                  errors.append(f\"Schema definition error at '{current_path}': Array element is 'object' but lacks 'schema' in 'element_schema'.\")\n",
    "                         elif elem_types:\n",
    "                              # If element schema is primitive, $elemMatch query should use operators applicable to that type\n",
    "                              # We need to validate the operators inside op_value against the primitive element_schema\n",
    "                              _validate_recursive_operators_against_schema(op_value, element_schema, errors, op_path, full_schema)\n",
    "\n",
    "                         else:\n",
    "                             errors.append(f\"Schema definition error at '{current_path}': Array field 'element_schema' lacks 'types'.\")\n",
    "\n",
    "                     else:\n",
    "                         errors.append(f\"Schema definition error at '{current_path}': Array field lacks 'element_schema' definition needed to validate '{op}'.\")\n",
    "\n",
    "                # Add more operator checks ($mod, $text, $where, geo, etc.) here if needed\n",
    "\n",
    "        else:\n",
    "            # Value is a direct match (implicit $eq)\n",
    "            query_value_type = get_value_type_name(query_value)\n",
    "            allowed_types = field_schema_info.get('types', set())\n",
    "\n",
    "            if not allowed_types:\n",
    "                errors.append(f\"Schema definition error at '{current_path}': Field lacks 'types' definition.\")\n",
    "            elif query_value_type not in allowed_types:\n",
    "                 # Allow null match if 'null' is an allowed type\n",
    "                 if query_value_type == 'null' and 'null' in allowed_types:\n",
    "                     pass # Valid null match\n",
    "                 else:\n",
    "                     # Special case: Allow int/long/double/decimal to match if any numeric type is allowed\n",
    "                     numeric_types = {'int', 'long', 'double', 'decimal'}\n",
    "                     if not (query_value_type in numeric_types and bool(allowed_types.intersection(numeric_types))):\n",
    "                         errors.append(f\"Type mismatch for field '{current_path}': Query uses type '{query_value_type}', but schema expects {allowed_types}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_recursive_operators_against_schema(operator_query, field_schema, errors, path_prefix, full_schema):\n",
    "     \"\"\"\n",
    "     Helper specifically for validating an operator block (like inside $elemMatch for primitives)\n",
    "     against a specific field schema definition.\n",
    "     \"\"\"\n",
    "     if not isinstance(operator_query, Mapping):\n",
    "         errors.append(f\"Invalid structure at '{path_prefix}': Expected an operator dictionary.\")\n",
    "         return\n",
    "\n",
    "     # Simulate the structure needed by the main validator by wrapping the schema\n",
    "     # This is a bit of a hack, cleaner ways might exist\n",
    "     temp_wrapper_schema = {\"_field_\": field_schema}\n",
    "     temp_wrapper_query = {\"_field_\": operator_query}\n",
    "\n",
    "     _validate_recursive(temp_wrapper_query, temp_wrapper_schema, errors, path_prefix=\"\", full_schema=full_schema) # path_prefix is tricky here, maybe adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "\n",
    "# 1. Define your expected schema (e.g., from the inference script)\n",
    "my_schema = {\n",
    "    'users': {\n",
    "        '_id': {'types': {'objectId'}},\n",
    "        'name': {'types': {'string'}},\n",
    "        'email': {'types': {'string', 'null'}},\n",
    "        'age': {'types': {'int', 'long'}}, # Allow int32 or int64\n",
    "        'isActive': {'types': {'bool'}},\n",
    "        'scores': {\n",
    "            'types': {'array'},\n",
    "            'element_schema': {'types': {'int'}}\n",
    "        },\n",
    "        'address': {\n",
    "            'types': {'object', 'null'}, # Address can be missing\n",
    "            'schema': {\n",
    "                'street': {'types': {'string'}},\n",
    "                'city': {'types': {'string'}},\n",
    "                'zip': {'types': {'string', 'int'}}, # Zip might be string or int\n",
    "                'coords': {\n",
    "                     'types': {'array'},\n",
    "                     'element_schema': {'types': {'double'}} # [lon, lat]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'tags':{\n",
    "            'types': {'array'},\n",
    "            'element_schema': {\n",
    "                'types': {'object'},\n",
    "                'schema': {\n",
    "                    'tag_id': {'types': {'int'}},\n",
    "                    'label': {'types': {'string'}}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Add other collections if needed\n",
    "}\n",
    "\n",
    "# Assume we are querying the 'users' collection\n",
    "collection_schema = my_schema.get('users', {}) # Get schema for the specific collection\n",
    "\n",
    "# 2. Define Queries to Validate\n",
    "valid_query_1 = {\n",
    "    'age': {'$gt': 30},\n",
    "    'isActive': True,\n",
    "    'address.city': 'Metropolis'\n",
    "}\n",
    "\n",
    "valid_query_2 = {\n",
    "    'email': None,\n",
    "    'scores': {'$in': [100, 95]},\n",
    "    'address.zip': '12345' # String zip is allowed by schema\n",
    "}\n",
    "\n",
    "valid_query_3 = {\n",
    "    '$and': [\n",
    "        {'age': {'$lte': 65}},\n",
    "        {'address.coords': {'$size': 2}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "valid_query_4 = {\n",
    "    'tags': {\n",
    "        '$elemMatch': {'label': 'important', 'tag_id': {'$gt': 10}}\n",
    "    }\n",
    "}\n",
    "\n",
    "invalid_query_1 = {\n",
    "    'age': 'old', # Type mismatch: age expects int/long\n",
    "    'status': 'active' # Field 'status' does not exist\n",
    "}\n",
    "\n",
    "invalid_query_2 = {\n",
    "    'address.country': 'USA', # Field 'address.country' does not exist\n",
    "    'scores': 50 # Type mismatch: scores expects array, query uses int\n",
    "}\n",
    "\n",
    "invalid_query_3 = {\n",
    "    'scores': {'$elemMatch': {'$gt': 90}} # $elemMatch on array of primitives needs operators applied correctly\n",
    "}\n",
    "\n",
    "invalid_query_4 = {\n",
    "     'address.zip': {'$gt': 'ABC'} # Comparing string zip code with string might be ok, but depends on strictness\n",
    "     # Our validator currently allows string comparison if 'string' is an allowed type\n",
    "}\n",
    "\n",
    "invalid_query_5 = {\n",
    "    'tags': {\n",
    "        '$elemMatch': {'name': 'vip'} # 'name' field doesn't exist in tags element schema\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validating Queries\n",
      "\n",
      "Validating: Valid Query 1\n",
      "Result: VALID\n",
      "\n",
      "Validating: Valid Query 2\n",
      "Result: INVALID\n",
      "  - Type mismatch for item in '$in' array at 'scores.$in[0]': Item type is 'int', but schema expects {'array'}.\n",
      "  - Type mismatch for item in '$in' array at 'scores.$in[1]': Item type is 'int', but schema expects {'array'}.\n",
      "\n",
      "Validating: Valid Query 3\n",
      "Result: VALID\n",
      "\n",
      "Validating: Valid Query 4\n",
      "Result: VALID\n",
      "\n",
      "Validating: Invalid Query 1\n",
      "Result: INVALID\n",
      "  - Type mismatch for field 'age': Query uses type 'string', but schema expects {'int', 'long'}.\n",
      "  - Invalid query key 'status': Field 'status' not found in schema at ''.\n",
      "\n",
      "Validating: Invalid Query 2\n",
      "Result: INVALID\n",
      "  - Invalid query key 'address.country': Field 'country' not found in schema at 'address'.\n",
      "  - Type mismatch for field 'scores': Query uses type 'int', but schema expects {'array'}.\n",
      "\n",
      "Validating: Invalid Query 3\n",
      "Result: VALID\n",
      "\n",
      "Validating: Invalid Query 4\n",
      "Result: VALID\n",
      "\n",
      "Validating: Invalid Query 5\n",
      "Result: INVALID\n",
      "  - Invalid query key 'tags.$elemMatch.name': Field 'name' not found in schema at 'tags.$elemMatch'.\n"
     ]
    }
   ],
   "source": [
    "# 3. Validate and Print Results\n",
    "print(\"--- Validating Queries\")\n",
    "\n",
    "queries_to_test = {\n",
    "    \"Valid Query 1\": valid_query_1,\n",
    "    \"Valid Query 2\": valid_query_2,\n",
    "    \"Valid Query 3\": valid_query_3,\n",
    "    \"Valid Query 4\": valid_query_4,\n",
    "    \"Invalid Query 1\": invalid_query_1,\n",
    "    \"Invalid Query 2\": invalid_query_2,\n",
    "    \"Invalid Query 3\": invalid_query_3, # This one is subtle depending on interpretation\n",
    "    \"Invalid Query 4\": invalid_query_4,\n",
    "    \"Invalid Query 5\": invalid_query_5,\n",
    "}\n",
    "\n",
    "for name, query in queries_to_test.items():\n",
    "    print(f\"\\nValidating: {name}\")\n",
    "    # print(f\"Query: {query}\") # Optional: print the query itself\n",
    "    errors = validate_query(query, collection_schema)\n",
    "    if not errors:\n",
    "        print(\"Result: VALID\")\n",
    "    else:\n",
    "        print(\"Result: INVALID\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
